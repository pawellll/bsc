@Misc{audacity,
title =    {AUDACITY - free open source digital audio editor and recording computer software application},
howpublished = {\url{http://audacity.pl/}},
}

@inproceedings{stateOfArt,
title={Music emotion recognition: A state of the art review},
author={Kim, Youngmoo E and Schmidt, Erik M and Migneco, Raymond and Morton, Brandon G and Richardson, Patrick and Scott, Jeffrey and Speck, Jacquelin A and Turnbull, Douglas},
booktitle={Proc. ISMIR},
pages={255--266},
year={2010},
organization={Citeseer},
howpublished = {\url{http://music.ece.drexel.edu/files/Navigation/Publications/Kim2010.pdf}},
}
note = {Dostęp:25.12.2015}

@inproceedings{musicANN1,
 title={Predicting emotion from music audio features using neural networks},
 author={Vempala, Naresh N and Russo, Frank A},
 booktitle={Proceedings of the 9th International Symposium on Computer Music Modeling and Retrieval (CMMR)},
 year={2012},
 organization={Lecture Notes in Computer Science London, UK}, howpublished = {\url{http://cmmr2012.eecs.qmul.ac.uk/sites/cmmr2012.eecs.qmul.ac.uk/files/pdf/papers/cmmr2012_submission_66.pdf}},
}
note = {Dostęp:25.12.2015}

@Article{musicANN2,
title={A neural network model for the prediction of musical emotions},
author={Coutinho, Eduardo and Cangelosi, Angelo},
journal={Advances in cognitive systems},
pages={331--368},
year={2010},
publisher={IET Publisher London, UK},
howpublished = {\url{https://www.researchgate.net/profile/Eduardo_Coutinho/publication/258099490_A_neural_network_model_for_the_prediction_of_musical_emotions/links/0c9605369e70b70c9c000000.pdf}},
}
note = {Dostęp:25.12.2015}

@Article{musicANN3,
  title={Automatic Music Emotion Classification Using Artificial Neural Network Based on Vocal and Instrumental Sound Timbres},
  author={Mokhsin, Mudiana Binti and Rosli, Nurlaila Binti and Adnan, Wan Adilah Wan and Manaf, Norehan Abdul},
  journal={New Trends in Software Methodologies, Tools and Techniques: Proceedings of the Thirteenth SoMeT\_14},
  volume={265},
  pages={3},
  year={2014},
  publisher={IOS Press},
howpublished = {\url{http://thescipub.com/PDF/jcssp.2014.2584.2592.pdf}},
}
note = {Dostęp:25.12.2015}

@inproceedings{musicLyrics,
title={Music Emotion Recognition from Lyrics: A Comparative Study},
  author={Malheiro, Ricardo and Panda, Renato and Gomes, Paulo and Paiva, R},
  year={2013},
  organization={6th International Workshop on Machine Learning and Music (MML13). Held in Conjunction with the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECMLPPKDD13)},
howpublished = {\url{http://www.ecmlpkdd2013.org/wp-content/uploads/2013/09/MLMU_Malheiro.pdf}},
}
note = {Dostęp:25.12.2015}

@Book{leksykon,
author={Ryszard Tadeusiewicz, Maciej Szaleniec},
title = {Leksykon Sieci Neuronowych},
publisher = {Wydawnictwo Fundacji "Projekt Nauka"},
address = {Wrocław},
journal ={},
year={2015}
}

@Book{tadeusiewicz,
author={Ryszard Tadeusiewicz},
title = {Sieci Neuronowe},
publisher = {Akademicka Oficyna Wydawnicza},
address = {Warszawa},
journal ={},
year={1993}
}

@misc{wykladInternet,
author={Jerzy Stefanowski},
title = {Wykład "Sztuczne sieci neuronowe"},
journal ={},
year={},
howpublished = {\url{http://www.cs.put.poznan.pl/jstefanowski/aed/TPDANN.pdf}},
note = {Dostęp:25.12.2015},
}

@book{phdWork,
  title={Automatic Classification of Musical Mood by Content Based Analysis},
  author={Laurier, Cyril},
  year={2011},
  publisher={Universitat Pompeu Fabra},
  howpublished = {\url{http://mtg.upf.edu/files/publications/PhD_Cyril_Laurier_2011_Music_Mood_Classification.pdf}},
}
[Dostęp:25.12.2015] 

@Article{briefIntroduction,
 title={A brief introduction to neural networks},
  author={Kriesel, David},
  journal={Retrieved August},
  volume={15},
  pages={2011},
  year={2007},
howpublished = {\url{http://www.dkriesel.com/_media/science/neuronalenetze-en-zeta2-2col-dkrieselcom.pdf}},

}
{Dostęp:25.12.2015}

@misc{signalProcessing,
  title={Introduction to signal processing},
  author={Orfanidis, Sophocles J},
  year={1995},
  publisher={Prentice-Hall, Inc.},
  howpublished = {\url{http://www.ece.rutgers.edu/~orfanidi/intro2sp/orfanidis-i2sp.pdf}},
  note={Dostęp:29.12.2015}
}
[Dostęp:28.12.2015]

@misc{fourierTransform,
	title={The Fourier Transform and its Applications},
	author={Brad Osgood},
	howpublished = {\url{https://see.stanford.edu/materials/lsoftaee261/book-fall-07.pdf}},
	note={Dostęp:29.12.2015}
}
[Dostęp:29.12.2015]

@misc{windowingNI,
	title={Understanding FFTs and Windowing},
	author={National Instruments White Papers},
	howpublished = {\url{http://www.ni.com/white-paper/4844/en/}},
	note={Dostęp:29.12.2015}
}
[Dostęp:29.12.2015]

@misc{equalLoudness,
	title={Replay Gain - A Proposed Standard},
	author={David Robinson},
	howpublished = {\url{http://replaygain.hydrogenaud.io/proposal/equal_loudness.html}},
	note={Dostęp:29.12.2015}	
}
[Dostęp:29.12.2015]

@misc{izofona,
	title={Hasło izofona},
	author={Słownik Języka Polskiego PWN},
	howpublished = {\url{http://encyklopedia.pwn.pl/haslo/;3915950}},
	note={Dostęp:29.12.2015}
}
[Dostęp:29.12.2015]

@misc{izofonyModel,
	title={Full Revision of International Standards for Equal-Loudness Level Contours ({ISO} 226)},
	howpublished = {\url{http://www.aist.go.jp/aist_e/latest_research/2003/20031114/20031114.html}},
	note={Dostęp:29.12.2015}
}
[Dostęp:29.12.2015]

@misc{obwiednia,
	author={Janusz Słupik},
	title={Dźwięk cyfrowy},
	howpublished = {\url{http://www.aist.go.jp/aist_e/latest_research/2003/20031114/20031114.html}},
	note={Dostęp:02.01.2016}
}
[Dostęp:02.01.2016]

@article{rollOff,
  title={Musical genre classification of audio signals},
  author={Tzanetakis, George and Cook, Perry},
  journal={Speech and Audio Processing, IEEE transactions on},
  volume={10},
  number={5},
  pages={293--302},
  year={2002},
  publisher={IEEE},
  howpublished = {\url{http://www.aist.go.jp/aist_e/latest_research/2003/20031114/20031114.html}}
}
[Dostęp:29.12.2015]

@misc{skala,
	author={Janusz Jusiak},
	title={Podstawowe pojęcia muzyczne},
	howpublished = {\url{http://bacon.umcs.lublin.pl/~jjusiak/dokumenty/konwersatoria/PodstawowePoj%C4%99ciaWMuzyce.pdf}},
	note={Dostęp:01.01.2016}
}
[Dostęp:01.01.2016]

@article{hpcp,
  title={Tonal description of music audio signals},
  author={G{\'o}mez Guti{\'e}rrez, Emilia and others},
  year={2006},
  publisher={Universitat Pompeu Fabra},
  howpublished = {\url{http://www.dtic.upf.edu/~egomez/thesis/emilia-PhD-2006.pdf}}
}
[Dostęp:01.01.2016]

@article{emotion,
  title={The circumplex model of affect: An integrative approach to affective neuroscience, cognitive development, and psychopathology},
  author={Posner, Jonathan and Russell, James A and Peterson, Bradley S},
  journal={Development and psychopathology},
  volume={17},
  number={03},
  pages={715--734},
  year={2005},
  publisher={Cambridge Univ Press},
  howpublished = {\url{http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2367156/pdf/nihms44490.pdf}}
}
[Dostęp:02.01.2016]

@conference {essentia,
	title = {ESSENTIA: an Audio Analysis Library for Music Information Retrieval},
	booktitle = {International Society for Music Information Retrieval Conference (ISMIR{\textquoteright}13)},
	year = {2013},
	month = {04/11/2013},
	pages = {493-498},
	address = {Curitiba, Brazil},
	abstract = {We present Essentia 2.0, an open-source C++ library for audio analysis and audio-based music information retrieval released under the Affero GPL license. It contains an extensive collection of reusable algorithms which implement audio input/output functionality, standard digital signal processing blocks, statistical characterization of data, and a large set of spectral, temporal, tonal and high-level music descriptors. The library is also wrapped in Python and includes a number of predefined executable extractors for the available music descriptors, which facilitates its use for fast prototyping and allows setting up research experiments very rapidly. Furthermore, it includes a Vamp plugin to be used with Sonic Visualiser for visualization purposes. The library is cross-platform and currently supports Linux, Mac OS X, and Windows systems. Essentia is designed with a focus on the robustness of the provided music descriptors and is optimized in terms of the computational cost of the algorithms. The provided functionality, specifically the music descriptors included in-the-box and signal processing algorithms, is easily expandable and allows for both research experiments and development of large-scale industrial applications.},
	author = {Bogdanov, D. and Nicolas Wack and Emilia G{\'o}mez and Sankalp Gulati and Herrera, P. and Mayor, O. and Gerard Roma and Salamon, J. and Zapata, J. and Serra, Xavier}
}

@inproceedings{dataSet,
author = {Soleymani, Mohammad and Caro, Micheal N. and Schmidt, Erik M. and Sha, Cheng-Ya
and Yang, Yi-Hsuan},
title = {1000 Songs for Emotional Analysis of Music},
booktitle = {Proceedings of the 2Nd ACM International Workshop on Crowdsourcing for Multimedia},
series = {CrowdMM ’13},
year = {2013},
isbn = {978-1-4503-2396-3},
location = {Barcelona, Spain},
pages = {1--6},
url = {http://doi.acm.org/10.1145/2506364.2506365},
doi = {10.1145/2506364.2506365},
publisher = {ACM},
address = {New York, NY, USA},
}


